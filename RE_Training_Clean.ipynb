{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17efc1ca",
   "metadata": {},
   "source": [
    "# Right Eye (RE) - Feature Detection Model Training\n",
    "\n",
    "This notebook provides a clean, organized pipeline for training models for Right Eye feature detection/estimation.\n",
    "It follows the same modular structure as the LE (Left Eye) and Face experiments.\n",
    "\n",
    "## Experiment Overview\n",
    "- **Dataset**: Right Eye images with feature labels\n",
    "- **Task**: Regress two continuous values (feature coordinates)\n",
    "- **Approaches**: Baseline model, Transfer Learning, From Scratch\n",
    "- **Note**: Same architecture and training strategy as LE and Face, applied to Right Eye data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1926dd0c",
   "metadata": {},
   "source": [
    "## Section 1: Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428b53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import custom modules\n",
    "from config import get_config\n",
    "from data_loader import load_images, CustomDataGenerator, get_augmentation_generator\n",
    "from model_architecture import create_and_compile_model\n",
    "from training_utils import train_model, plot_training_results, save_history_to_json, get_callbacks\n",
    "from system_monitoring import print_system_info\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed47237",
   "metadata": {},
   "source": [
    "## Section 2: System Information & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c9474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print system information\n",
    "print_system_info()\n",
    "\n",
    "# Get experiment configuration for Right Eye\n",
    "experiment = 'RE'\n",
    "config = get_config(experiment)\n",
    "\n",
    "print(f\"\\nExperiment: {config['experiment_info']['name']}\")\n",
    "print(f\"Image Size: {config['image_size']}\")\n",
    "print(f\"Batch Size: {config['batch_size']}\")\n",
    "print(f\"Epochs: {config['epochs']}\")\n",
    "print(f\"Learning Rate: {config['learning_rate']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a3e620",
   "metadata": {},
   "source": [
    "## Section 3: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe26579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get experiment info\n",
    "exp_info = config['experiment_info']\n",
    "\n",
    "print(\"Loading baseline training data...\")\n",
    "train_samples, train_labels = load_images(\n",
    "    exp_info['baseline'],\n",
    "    image_size=config['image_size']\n",
    ")\n",
    "\n",
    "print(\"\\nLoading test data...\")\n",
    "test_samples, test_labels = load_images(\n",
    "    exp_info['test'],\n",
    "    image_size=config['image_size']\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain samples shape: {train_samples.shape}\")\n",
    "print(f\"Train labels shape: {train_labels.shape}\")\n",
    "print(f\"Test samples shape: {test_samples.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faceedbb",
   "metadata": {},
   "source": [
    "## Section 4: Create Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b14b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmentation generator\n",
    "datagen = get_augmentation_generator()\n",
    "\n",
    "# Create custom data generators\n",
    "train_generator = CustomDataGenerator(\n",
    "    train_samples, train_labels,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    datagen=datagen\n",
    ")\n",
    "\n",
    "test_generator = CustomDataGenerator(\n",
    "    test_samples, test_labels,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    datagen=None\n",
    ")\n",
    "\n",
    "print(f\"Training batches per epoch: {len(train_generator)}\")\n",
    "print(f\"Test batches per epoch: {len(test_generator)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c7aadb",
   "metadata": {},
   "source": [
    "## Section 5: Train Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1665f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = create_and_compile_model(\n",
    "    input_shape=(config['image_size'], config['image_size'], 3),\n",
    "    dense_units=96,\n",
    "    dropout_rate=config['dropout_rate'],\n",
    "    learning_rate=config['learning_rate']\n",
    ")\n",
    "\n",
    "print(\"Model created and compiled!\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b5909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get callbacks\n",
    "callbacks = get_callbacks(\n",
    "    patience_early_stopping=config['patience_early_stopping'],\n",
    "    patience_reduce_lr=config['patience_reduce_lr'],\n",
    "    factor_reduce_lr=config['factor_reduce_lr'],\n",
    "    min_learning_rate=config['min_learning_rate']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "results = train_model(\n",
    "    model,\n",
    "    train_generator,\n",
    "    test_generator,\n",
    "    epochs=config['epochs'],\n",
    "    callbacks=callbacks,\n",
    "    model_name=\"participant_baseline\"\n",
    ")\n",
    "\n",
    "history = results['history']\n",
    "training_time = results['time']\n",
    "\n",
    "print(f\"\\nTraining completed in {training_time['hours']:.2f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2848b152",
   "metadata": {},
   "source": [
    "## Section 6: Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3288402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training results\n",
    "plot_training_results(history, model_name=\"(participant_baseline)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3649c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Epochs trained: {len(train_loss)}\")\n",
    "print(f\"\\nFinal Training Loss: {train_loss[-1]:.6f}\")\n",
    "print(f\"Final Validation Loss: {val_loss[-1]:.6f}\")\n",
    "print(f\"\\nBest Validation Loss: {min(val_loss):.6f} (epoch {np.argmin(val_loss)+1})\")\n",
    "print(f\"Best Validation MAE: {min(val_mae):.6f} (epoch {np.argmin(val_mae)+1})\")\n",
    "print(f\"\\nTraining Time: {training_time['hours']:.2f} hours\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f0d50",
   "metadata": {},
   "source": [
    "## Section 7: Save Model & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e029b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = 'participant_baseline'\n",
    "model.save(f'{model_name}.keras')\n",
    "print(f\"Model saved as {model_name}.keras\")\n",
    "\n",
    "# Save training history\n",
    "save_history_to_json(history, f'{model_name}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33af2663",
   "metadata": {},
   "source": [
    "## Section 8: Transfer Learning with Different Dataset Sizes\n",
    "\n",
    "Fine-tune the baseline model with different amounts of Ola-augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc0ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = 'participant_baseline'\n",
    "model.save(f'{model_name}.keras')\n",
    "print(f\"Model saved as {model_name}.keras\")\n",
    "\n",
    "# Save training history\n",
    "save_history_to_json(history, f'{model_name}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generators for transfer learning\n",
    "ola_train_gen = CustomDataGenerator(\n",
    "    ola_train_samples, ola_train_labels,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "ola_test_gen = CustomDataGenerator(\n",
    "    test_samples, test_labels,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load baseline model for fine-tuning\n",
    "from tensorflow.keras.models import load_model\n",
    "model_ft = load_model(f'{model_name}.keras')\n",
    "\n",
    "# Fine-tune\n",
    "callbacks_ft = get_callbacks(\n",
    "    patience_early_stopping=config['patience_early_stopping'],\n",
    "    patience_reduce_lr=config['patience_reduce_lr'],\n",
    "    factor_reduce_lr=config['factor_reduce_lr'],\n",
    "    min_learning_rate=config['min_learning_rate']\n",
    ")\n",
    "\n",
    "results_ft = train_model(\n",
    "    model_ft,\n",
    "    ola_train_gen,\n",
    "    ola_test_gen,\n",
    "    epochs=config['epochs'],\n",
    "    callbacks=callbacks_ft,\n",
    "    model_name=f\"participant_transfer_{dataset_key}\"\n",
    ")\n",
    "\n",
    "history_ft = results_ft['history']\n",
    "print(f\"\\nTransfer learning completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dc8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot transfer learning results\n",
    "plot_training_results(history_ft, model_name=f\"(Right Eye Transfer - {dataset_key} Ola)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca06c1",
   "metadata": {},
   "source": [
    "## Section 9: From-Scratch Training with Ola Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7a11a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model for from-scratch training\n",
    "model_scratch = create_and_compile_model(\n",
    "    input_shape=(config['image_size'], config['image_size'], 3),\n",
    "    dense_units=96,\n",
    "    dropout_rate=config['dropout_rate'],\n",
    "    learning_rate=config['learning_rate']\n",
    ")\n",
    "\n",
    "callbacks_scratch = get_callbacks(\n",
    "    patience_early_stopping=config['patience_early_stopping'],\n",
    "    patience_reduce_lr=config['patience_reduce_lr'],\n",
    "    factor_reduce_lr=config['factor_reduce_lr'],\n",
    "    min_learning_rate=config['min_learning_rate']\n",
    ")\n",
    "\n",
    "results_scratch = train_model(\n",
    "    model_scratch,\n",
    "    ola_train_gen,\n",
    "    ola_test_gen,\n",
    "    epochs=config['epochs'],\n",
    "    callbacks=callbacks_scratch,\n",
    "    model_name=f\"participant_scratch_{dataset_key}\"\n",
    ")\n",
    "\n",
    "history_scratch = results_scratch['history']\n",
    "print(f\"\\nFrom-scratch training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf9b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all three approaches\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs_baseline = range(1, len(history.history['val_loss']) + 1)\n",
    "epochs_ft = range(1, len(history_ft.history['val_loss']) + 1)\n",
    "epochs_scratch = range(1, len(history_scratch.history['val_loss']) + 1)\n",
    "\n",
    "# Validation Loss\n",
    "axes[0].plot(epochs_baseline, history.history['val_loss'], 'b-o', label='Baseline', linewidth=2, markersize=3)\n",
    "axes[0].plot(epochs_ft, history_ft.history['val_loss'], 'g-s', label=f'Transfer (Ola-{dataset_key})', linewidth=2, markersize=3)\n",
    "axes[0].plot(epochs_scratch, history_scratch.history['val_loss'], 'r-^', label=f'From-Scratch (Ola-{dataset_key})', linewidth=2, markersize=3)\n",
    "axes[0].set_title('Validation Loss Comparison', fontsize=14)\n",
    "axes[0].set_xlabel('Epochs')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Validation MAE\n",
    "axes[1].plot(epochs_baseline, history.history['val_mae'], 'b-o', label='Baseline', linewidth=2, markersize=3)\n",
    "axes[1].plot(epochs_ft, history_ft.history['val_mae'], 'g-s', label=f'Transfer (Ola-{dataset_key})', linewidth=2, markersize=3)\n",
    "axes[1].plot(epochs_scratch, history_scratch.history['val_mae'], 'r-^', label=f'From-Scratch (Ola-{dataset_key})', linewidth=2, markersize=3)\n",
    "axes[1].set_title('Validation MAE Comparison', fontsize=14)\n",
    "axes[1].set_xlabel('Epochs')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16986c9d",
   "metadata": {},
   "source": [
    "## Section 10: Conclusions & Notes\n",
    "\n",
    "- Same architecture and training strategy as the LE (Left Eye) and Face experiments\n",
    "- **Baseline Model**: Trained on data without Ola augmentation\n",
    "- **Transfer Learning**: Fine-tunes baseline with Ola-augmented data\n",
    "- **From-Scratch**: Trains new model directly on Ola-augmented data\n",
    "\n",
    "Compare the results to determine which approach works best for Right Eye feature detection."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
